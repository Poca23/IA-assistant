# app/test_sync_export.py
"""
Tests unitaires module sync_export
Validation : Export filtrÃ©, Backup, Restore
âš ï¸ UTILISE DATA TEST SÃ‰PARÃ‰E
"""
import json
import shutil
from pathlib import Path
from datetime import datetime
from .sync_export import SyncExport

# ğŸ” CONFIGURATION TEST
TEST_DATA_DIR = Path("data_test")
REAL_DATA_DIR = Path("data")

def backup_real_data():
    """Sauvegarde donnÃ©es rÃ©elles avant tests"""
    print("ğŸ” Sauvegarde donnÃ©es rÃ©elles...")
    
    if REAL_DATA_DIR.exists():
        backup_dir = Path("data_backup_test")
        if backup_dir.exists():
            shutil.rmtree(backup_dir)
        shutil.copytree(REAL_DATA_DIR, backup_dir)
        print(f"âœ… Backup crÃ©Ã© : {backup_dir}")
    else:
        print("âš ï¸ Aucune donnÃ©e rÃ©elle Ã  sauvegarder")

def restore_real_data():
    """Restaure donnÃ©es rÃ©elles aprÃ¨s tests"""
    print("\nğŸ”„ Restauration donnÃ©es rÃ©elles...")
    
    backup_dir = Path("data_backup_test")
    if backup_dir.exists():
        if REAL_DATA_DIR.exists():
            shutil.rmtree(REAL_DATA_DIR)
        shutil.copytree(backup_dir, REAL_DATA_DIR)
        shutil.rmtree(backup_dir)
        print("âœ… DonnÃ©es rÃ©elles restaurÃ©es")
    else:
        print("âš ï¸ Aucun backup Ã  restaurer")

def setup_test_environment():
    """Configure environnement test isolÃ©"""
    print("ğŸ”§ Configuration environnement test...")
    
    # Nettoyage ancien test
    if TEST_DATA_DIR.exists():
        shutil.rmtree(TEST_DATA_DIR)
    
    # CrÃ©ation structure test
    TEST_DATA_DIR.mkdir(parents=True, exist_ok=True)
    (TEST_DATA_DIR / "knowledge" / "general").mkdir(parents=True, exist_ok=True)
    (TEST_DATA_DIR / "knowledge" / "personal").mkdir(parents=True, exist_ok=True)
    (TEST_DATA_DIR / "backups").mkdir(exist_ok=True)
    
    print(f"âœ… Environnement test : {TEST_DATA_DIR}")

def setup_test_data():
    """CrÃ©ation donnÃ©es test directement dans fichiers JSON"""
    print("\nğŸ“ CrÃ©ation donnÃ©es test...")
    
    kb_dir = TEST_DATA_DIR / "knowledge"
    
    # Culture
    culture_file = kb_dir / "general" / "culture.json"
    culture_data = {
        "entries": [{
            "id": "test_culture_1",
            "question": "Qui a peint la Joconde ?",
            "answer": "LÃ©onard de Vinci",
            "tags": ["art", "peinture"],
            "category": "general",
            "subcategory": "culture",
            "created": datetime.now().strftime("%Y-%m-%d"),
            "updated": datetime.now().strftime("%Y-%m-%d")
        }],
        "metadata": {
            "category": "general",
            "subcategory": "culture",
            "total_entries": 1,
            "last_updated": datetime.now().isoformat()
        }
    }
    with open(culture_file, 'w', encoding='utf-8') as f:
        json.dump(culture_data, f, ensure_ascii=False, indent=2)
    
    # Sciences
    sciences_file = kb_dir / "general" / "sciences.json"
    sciences_data = {
        "entries": [{
            "id": "test_sciences_1",
            "question": "Quelle est la vitesse de la lumiÃ¨re ?",
            "answer": "299 792 458 m/s",
            "tags": ["physique", "constante"],
            "category": "general",
            "subcategory": "sciences",
            "created": datetime.now().strftime("%Y-%m-%d"),
            "updated": datetime.now().strftime("%Y-%m-%d")
        }],
        "metadata": {
            "category": "general",
            "subcategory": "sciences",
            "total_entries": 1,
            "last_updated": datetime.now().isoformat()
        }
    }
    with open(sciences_file, 'w', encoding='utf-8') as f:
        json.dump(sciences_data, f, ensure_ascii=False, indent=2)
    
    # Cuisine
    cuisine_file = kb_dir / "personal" / "cuisine.json"
    cuisine_data = {
        "entries": [{
            "id": "test_cuisine_1",
            "question": "Temps cuisson pÃ¢tes ?",
            "answer": "8-12 minutes selon type",
            "tags": ["cuisine", "conseil"],
            "category": "personal",
            "subcategory": "cuisine",
            "created": datetime.now().strftime("%Y-%m-%d"),
            "updated": datetime.now().strftime("%Y-%m-%d")
        }],
        "metadata": {
            "category": "personal",
            "subcategory": "cuisine",
            "total_entries": 1,
            "last_updated": datetime.now().isoformat()
        }
    }
    with open(cuisine_file, 'w', encoding='utf-8') as f:
        json.dump(cuisine_data, f, ensure_ascii=False, indent=2)
    
    print("âœ… 3 entrÃ©es test crÃ©Ã©es")

def get_test_sync():
    """Instance SyncExport configurÃ©e pour tests"""
    sync = SyncExport()
    # Override chemins vers environnement test
    sync.data_dir = TEST_DATA_DIR / "knowledge"
    sync.backup_dir = TEST_DATA_DIR / "backups"
    sync.logs_file = TEST_DATA_DIR / "export_logs.json"
    return sync

def test_export_filters():
    """Test 1 : Export avec filtres"""
    print("\nğŸ§ª TEST 1 : Export filtrÃ©")
    
    sync = get_test_sync()
    
    # Export sans filtre (tout)
    success, msg, data = sync.export_by_filters()
    assert success, f"Export complet Ã©chouÃ© : {msg}"
    assert data is not None, "Pas de donnÃ©es retournÃ©es"
    assert data["metadata"]["total_entries"] >= 3, f"Pas assez d'entrÃ©es : {data['metadata']['total_entries']}"
    print(f"âœ… Export complet : {data['metadata']['total_entries']} entrÃ©es")
    
    # Export catÃ©gorie "general"
    success, msg, data = sync.export_by_filters(category="general")
    assert success, f"Export catÃ©gorie Ã©chouÃ© : {msg}"
    assert data["metadata"]["total_entries"] >= 2, "Filtre catÃ©gorie KO"
    print(f"âœ… Export catÃ©gorie 'general' : {data['metadata']['total_entries']} entrÃ©es")
    
    # Export par tag
    success, msg, data = sync.export_by_filters(tags=["cuisine"])
    assert success, f"Export tags Ã©chouÃ© : {msg}"
    assert data["metadata"]["total_entries"] >= 1, "Filtre tags KO"
    print(f"âœ… Export tag 'cuisine' : {data['metadata']['total_entries']} entrÃ©e(s)")
    
    # Export date (aujourd'hui)
    today = datetime.now().strftime("%Y-%m-%d")
    success, msg, data = sync.export_by_filters(date_from=today)
    assert success, f"Export date Ã©chouÃ© : {msg}"
    print(f"âœ… Export date >= {today} : {data['metadata']['total_entries']} entrÃ©e(s)")

def test_backup_full():
    """Test 2 : Backup complet"""
    print("\nğŸ§ª TEST 2 : Backup complet")
    
    sync = get_test_sync()
    
    success, msg, zip_path = sync.backup_full_knowledge()
    assert success, f"Backup Ã©chouÃ© : {msg}"
    
    # VÃ©rification fichier
    backup_file = Path(zip_path)
    assert backup_file.exists(), "ZIP backup absent"
    assert backup_file.stat().st_size > 0, "ZIP vide"
    
    # VÃ©rification mÃ©tadonnÃ©es
    meta_file = Path(f"{zip_path}.meta.json")
    assert meta_file.exists(), "MÃ©tadonnÃ©es absentes"
    
    with open(meta_file, 'r') as f:
        meta = json.load(f)
    assert "backup_date" in meta, "Date backup manquante"
    assert meta["files_count"] > 0, "Aucun fichier backupÃ©"
    
    print(f"âœ… Backup crÃ©Ã© : {backup_file.name}")
    print(f"   ğŸ“Š Taille : {round(backup_file.stat().st_size / 1024, 2)} KB")
    print(f"   ğŸ“ Fichiers : {meta['files_count']}")
    
    return zip_path

def test_restore_merge(backup_zip):
    """Test 3 : Restore mode merge"""
    print("\nğŸ§ª TEST 3 : Restore (merge)")
    
    sync = get_test_sync()
    
    # Ajout entrÃ©e supplÃ©mentaire
    test_dir = TEST_DATA_DIR / "knowledge" / "test"
    test_dir.mkdir(parents=True, exist_ok=True)
    test_file = test_dir / "test.json"
    
    test_data = {
        "entries": [{
            "id": "test_restore_1",
            "question": "Question test restore",
            "answer": "RÃ©ponse test",
            "tags": ["test"],
            "category": "test",
            "created": datetime.now().strftime("%Y-%m-%d")
        }],
        "metadata": {"category": "test", "total_entries": 1}
    }
    with open(test_file, 'w', encoding='utf-8') as f:
        json.dump(test_data, f, ensure_ascii=False, indent=2)
    
    # Restore merge
    success, msg, stats = sync.restore_from_backup(backup_zip, mode="merge")
    assert success, f"Restore Ã©chouÃ© : {msg}"
    assert stats["files_restored"] > 0, "Aucun fichier restaurÃ©"
    
    print(f"âœ… Restore merge : {stats['entries_added']} entrÃ©es ajoutÃ©es")
    print(f"   ğŸ“ Fichiers : {stats['files_restored']}")
    
    # VÃ©rification entrÃ©e test toujours lÃ 
    assert test_file.exists(), "EntrÃ©e test disparue en mode merge"

def test_restore_replace(backup_zip):
    """Test 4 : Restore mode replace"""
    print("\nğŸ§ª TEST 4 : Restore (replace)")
    
    sync = get_test_sync()
    
    # Ajout entrÃ©e temporaire
    temp_dir = TEST_DATA_DIR / "knowledge" / "temp"
    temp_dir.mkdir(parents=True, exist_ok=True)
    temp_file = temp_dir / "temp.json"
    
    temp_data = {
        "entries": [{
            "id": "temp_1",
            "question": "Question temp",
            "answer": "Doit disparaÃ®tre",
            "tags": ["temp"],
            "category": "temp"
        }],
        "metadata": {"category": "temp", "total_entries": 1}
    }
    with open(temp_file, 'w', encoding='utf-8') as f:
        json.dump(temp_data, f, ensure_ascii=False, indent=2)
    
    # Restore replace
    success, msg, stats = sync.restore_from_backup(backup_zip, mode="replace")
    assert success, f"Restore replace Ã©chouÃ© : {msg}"
    
    print(f"âœ… Restore replace : {stats['files_restored']} fichiers")
    
    # VÃ©rification entrÃ©e temp disparue
    assert not temp_file.exists(), "EntrÃ©e temp toujours prÃ©sente"

def test_backups_list():
    """Test 5 : Liste backups"""
    print("\nğŸ§ª TEST 5 : Liste backups")
    
    sync = get_test_sync()
    backups = sync.get_backups_list()
    
    assert len(backups) > 0, "Aucun backup listÃ©"
    
    print(f"âœ… {len(backups)} backup(s) disponible(s)")
    for backup in backups[:3]:
        print(f"   ğŸ“¦ {backup['filename']} ({backup['size_mb']} MB)")

def test_logs():
    """Test 6 : VÃ©rification logs"""
    print("\nğŸ§ª TEST 6 : Logs opÃ©rations")
    
    sync = get_test_sync()
    logs_file = sync.logs_file
    
    if not logs_file.exists():
        print("âš ï¸ Fichier logs absent (normal si aucune opÃ©ration)")
        return
    
    with open(logs_file, 'r') as f:
        logs = json.load(f)
    
    assert len(logs) > 0, "Logs vides"
    
    operations = set(log["operation"] for log in logs)
    print(f"âœ… {len(logs)} opÃ©rations loggÃ©es")
    print(f"   ğŸ”§ Types : {', '.join(operations)}")

def cleanup_tests():
    """Nettoyage aprÃ¨s tests"""
    print("\nğŸ§¹ Nettoyage environnement test...")
    
    if TEST_DATA_DIR.exists():
        shutil.rmtree(TEST_DATA_DIR)
    
    print("âœ… Nettoyage terminÃ©")

def run_all_tests():
    """ExÃ©cution suite complÃ¨te"""
    print("=" * 60)
    print("ğŸ§ª TESTS SYNC_EXPORT - Suite complÃ¨te")
    print("=" * 60)
    
    try:
        # ğŸ” Backup donnÃ©es rÃ©elles
        backup_real_data()
        
        # Setup environnement test
        setup_test_environment()
        setup_test_data()
        
        # Tests
        test_export_filters()
        backup_zip = test_backup_full()
        test_restore_merge(backup_zip)
        test_restore_replace(backup_zip)
        test_backups_list()
        test_logs()
        
        # Cleanup
        cleanup_tests()
        
        # ğŸ”„ Restauration donnÃ©es rÃ©elles
        restore_real_data()
        
        print("\n" + "=" * 60)
        print("âœ… TOUS LES TESTS PASSÃ‰S !")
        print("=" * 60)
        
        return True
        
    except AssertionError as e:
        print(f"\nâŒ TEST Ã‰CHOUÃ‰ : {e}")
        restore_real_data()
        return False
    except Exception as e:
        print(f"\nâŒ ERREUR : {e}")
        import traceback
        traceback.print_exc()
        restore_real_data()
        return False

if __name__ == "__main__":
    run_all_tests()
